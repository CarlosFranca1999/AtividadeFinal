
# ğŸ§¬ Atividade Final de InteligÃªncia Artificial


ClassificaÃ§Ã£o Supervisionada com o Dataset Titanic

Este repositÃ³rio contÃ©m a atividade final da disciplina de InteligÃªncia Artificial, cujo objetivo Ã© aplicar tÃ©cnicas de classificaÃ§Ã£o supervisionada utilizando o conjunto de dados Titanic e comparando o desempenho entre mÃºltiplos modelos do scikit-learn e XGBoost.

ğŸ“Œ Objetivo do Projeto

Construir, treinar, avaliar e comparar modelos de classificaÃ§Ã£o binÃ¡ria capazes de prever a sobrevivÃªncia de passageiros do Titanic, utilizando diferentes algoritmos:

XGBoostClassifier

RandomForestClassifier

DecisionTreeClassifier

O projeto inclui:

PrÃ©-processamento completo dos dados

ConstruÃ§Ã£o de pipelines

Treinamento com validaÃ§Ã£o

AvaliaÃ§Ã£o por mÃºltiplas mÃ©tricas

VisualizaÃ§Ãµes (ROC, Precision-Recall, matrizes de confusÃ£o)

AnÃ¡lise comparativa dos modelos

#  ğŸ“‚ Estrutura do Notebook

1. ImportaÃ§Ã£o das Bibliotecas

Carregamento das bibliotecas necessÃ¡rias para manipulaÃ§Ã£o de dados, modelagem e visualizaÃ§Ã£o.

2. Carga e PreparaÃ§Ã£o dos Dados

ImportaÃ§Ã£o do dataset Titanic

SeleÃ§Ã£o das features mais relevantes

DefiniÃ§Ã£o da variÃ¡vel alvo (Survived)

SeparaÃ§Ã£o estratificada (train/test split)

3. PrÃ©-processamento

Uso de pipelines para padronizar o tratamento de dados:

# ğŸ“Š VariÃ¡veis NumÃ©ricas

ImputaÃ§Ã£o de valores ausentes

PadronizaÃ§Ã£o via StandardScaler

# ğŸ·ï¸ VariÃ¡veis CategÃ³ricas

ImputaÃ§Ã£o de categorias faltantes

CodificaÃ§Ã£o com OneHotEncoder

Ambos combinados em um ColumnTransformer.

4. Treinamento dos Modelos

Modelos implementados:

Ãrvore de DecisÃ£o (DecisionTreeClassifier)

Floresta AleatÃ³ria (RandomForestClassifier)

XGBoostClassifier

Cada modelo Ã© integrado a um pipeline completo (prÃ©-processamento + modelo).

5. AvaliaÃ§Ã£o dos Modelos

MÃ©tricas utilizadas:

AcurÃ¡cia

Precision

Recall

F1-score

AUC-ROC

AlÃ©m disso, sÃ£o geradas visualizaÃ§Ãµes:

ğŸ“ˆ Curva ROC

ğŸ“‰ Curva Precision-Recall

ğŸ”² Matriz de confusÃ£o

â±ï¸ Tempo de execuÃ§Ã£o para medir custo computacional

6. AnÃ¡lise Comparativa

O notebook discute:

Qual modelo apresentou melhor desempenho

DiferenÃ§as entre as curvas ROC/PR

IndÃ­cios de overfitting

Dificuldades no prÃ©-processamento

InterpretaÃ§Ã£o dos resultados obtidos

ğŸ› ï¸ Tecnologias Utilizadas

Python 3.x

Pandas

NumPy

Scikit-learn

XGBoost

Matplotlib

Seaborn

# ğŸš€ Como Executar

Instale as dependÃªncias:

pip install -r requirements.txt


Abra o notebook:

jupyter notebook ğŸ§¬_Atividade_Final_de_InteligÃªncia_Artificial.ipynb

Adiciona dataset 

Execute sequencialmente todas as cÃ©lulas.

# ğŸ“Œ ConclusÃµes Principais (Resumo)

O modelo que geralmente apresenta melhor desempenho no dataset Titanic costuma ser o XGBoostClassifier, devido Ã  sua capacidade de capturar interaÃ§Ãµes e nÃ£o linearidades.

O RandomForestClassifier tambÃ©m entrega resultados estÃ¡veis e com menor risco de overfitting.

A DecisionTreeClassifier Ã© mais simples e interpretÃ¡vel, porÃ©m tende a superajustar quando nÃ£o regularizada.

O uso de pipelines e prÃ©-processamento adequado foi fundamental para garantir consistÃªncia nos resultados.

